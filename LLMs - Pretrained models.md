LLMs - Pretrained models

lamDA 3.2 Seven billion parmeter - on google colab

collect labeled data 

train the model



fine tuning is domain specific model



embedding models? generates numerical representations of the data.



using pymupdf extract documents text

prepare chunks

Embedding 

vector



### 3-Step Pipeline

1\. Load

2\. Split (500 words chunk)

3\. Embed \& Store in vector DB



### Hugging Face token 

hf\_cGrwKPJNseLbdBoAPKpBqfvFgMIIqczIVa







